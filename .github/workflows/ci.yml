name: Evals

on:
  pull_request:
    types:
      - opened
      - synchronize
      - labeled

env:
  EVAL_MODELS: "gpt-4o,gpt-4o-mini,claude-3-5-sonnet-latest"
  EVAL_CATEGORIES: "observe,act,combination,extract,text_extract"

jobs:
  ####################################################################
  # 1. DETERMINE-EVALS
  #
  #    Checks if the PR is on the main branch or if it has
  #    certain labels, then sets outputs to instruct
  #    which specialized evals should run.
  ####################################################################
  determine-evals:
    runs-on: ubuntu-latest
    outputs:
      run-extract: ${{ steps.check-labels.outputs.run-extract }}
      run-act: ${{ steps.check-labels.outputs.run-act }}
      run-observe: ${{ steps.check-labels.outputs.run-observe }}
      run-text-extract: ${{ steps.check-labels.outputs.run-text-extract }}
    steps:
      - id: check-labels
        run: |
          # Default to running all specialized tests on main branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "Running all specialized categories for main branch"
            echo "run-extract=true" >> $GITHUB_OUTPUT
            echo "run-act=true" >> $GITHUB_OUTPUT
            echo "run-observe=true" >> $GITHUB_OUTPUT
            echo "run-text-extract=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Otherwise, check for specific labels
          echo "run-extract=${{ contains(github.event.pull_request.labels.*.name, 'extract') }}" >> $GITHUB_OUTPUT
          echo "run-act=${{ contains(github.event.pull_request.labels.*.name, 'act') }}" >> $GITHUB_OUTPUT
          echo "run-observe=${{ contains(github.event.pull_request.labels.*.name, 'observe') }}" >> $GITHUB_OUTPUT
          echo "run-text-extract=${{ contains(github.event.pull_request.labels.*.name, 'text-extract') }}" >> $GITHUB_OUTPUT

  ####################################################################
  # 2. LINT JOB
  ####################################################################
  run-lint:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Run Lint
        run: npm run lint

  ####################################################################
  # 3. BUILD JOB
  ####################################################################
  run-build:
    runs-on: ubuntu-latest
    needs: [run-lint]
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Run Build
        run: npm run build

  ####################################################################
  # 4. E2E TESTS JOB
  ####################################################################
  run-e2e-tests:
    needs: [run-lint, run-build]
    runs-on: ubuntu-latest
    timeout-minutes: 50
    env:
      HEADLESS: true

    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Install Playwright browsers
        run: npm exec playwright install --with-deps

      - name: Build Stagehand
        run: npm run build

      - name: Run E2E Tests (Deterministic Playwright)
        run: npm run e2e

  ####################################################################
  # 5. E2E-BB (Browserbase) TESTS JOB
  ####################################################################
  run-e2e-bb-tests:
    needs: [run-e2e-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 50
    if: >
      github.event_name == 'push' ||
      (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository)

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
      BROWSERBASE_PROJECT_ID: ${{ secrets.BROWSERBASE_PROJECT_ID }}
      HEADLESS: true

    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Install Playwright browsers
        run: npm exec playwright install --with-deps

      - name: Build Stagehand
        run: npm run build

      - name: Run E2E Tests (browserbase)
        run: npm run e2e:bb

  ####################################################################
  # 6. COMBINATION EVALS JOB (DUMMY DATA)
  ####################################################################
  run-combination-evals:
    needs: [run-e2e-bb-tests, run-e2e-tests, determine-evals]
    runs-on: ubuntu-latest
    timeout-minutes: 40
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      BRAINTRUST_API_KEY: ${{ secrets.BRAINTRUST_API_KEY }}
      BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
      BROWSERBASE_PROJECT_ID: ${{ secrets.BROWSERBASE_PROJECT_ID }}
      HEADLESS: true
      EVAL_ENV: browserbase

    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Build Stagehand
        run: npm run build

      - name: Install Playwright browsers
        run: npm exec playwright install --with-deps

      - name: Run Combination Evals (Dummy)
        run: |
          echo "Pretending to run combination eval..."
          # Write out a dummy eval-summary.json:
          cat <<EOF > eval-summary.json
          {
            "experimentName": "dummyCombination",
            "categories": {
              "combination": 90
            }
          }
          EOF

      - name: Log Combination Evals Performance
        run: |
          experimentName=$(jq -r '.experimentName' eval-summary.json)
          echo "View results at https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentName}"
          if [ -f eval-summary.json ]; then
            combination_score=$(jq '.categories.combination' eval-summary.json)
            echo "Combination category score: $combination_score%"
            exit 0
          else
            echo "Eval summary not found for combination category. Failing CI."
            exit 1
          fi

  ####################################################################
  # 7. SPECIALIZED EVALS (Single Job, Multi-Step)
  #
  #    This job replaces the old separate jobs for:
  #      - extract
  #      - text-extract
  #      - act
  #      - observe
  #
  #    It runs them in sequence, each block gated by an IF condition
  #    so we skip any eval steps that are not labeled.
  ####################################################################
  run-specialized-evals:
    needs: [determine-evals, run-combination-evals]
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      BRAINTRUST_API_KEY: ${{ secrets.BRAINTRUST_API_KEY }}
      BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
      BROWSERBASE_PROJECT_ID: ${{ secrets.BROWSERBASE_PROJECT_ID }}
      HEADLESS: true
      EVAL_ENV: browserbase

    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install --no-frozen-lockfile

      - name: Build Stagehand
        run: npm run build

      - name: Install Playwright browsers
        run: npm exec playwright install --with-deps

      ############################################################
      # 7A. EXTRACT EVALS (if label = 'extract')
      ############################################################
      - name: Run Extract Evals (domExtract)
        if: ${{ needs.determine-evals.outputs.run-extract == 'true' }}
        run: |
          echo "Pretending to run extract eval with domExtract..."
          cat <<EOF > eval-summary-extract-dom.json
          {
            "experimentName": "dummyExtractDom",
            "categories": {
              "extract": 85
            }
          }
          EOF

      - name: Run Extract Evals (textExtract)
        if: ${{ needs.determine-evals.outputs.run-extract == 'true' }}
        run: |
          echo "Pretending to run extract eval with textExtract..."
          cat <<EOF > eval-summary-extract-text.json
          {
            "experimentName": "dummyExtractText",
            "categories": {
              "extract": 92
            }
          }
          EOF

      - name: Log and Compare Extract Evals Performance
        if: ${{ needs.determine-evals.outputs.run-extract == 'true' }}
        run: |
          # Check domExtract results
          if [ -f eval-summary-extract-dom.json ]; then
            experimentNameDom=$(jq -r '.experimentName' eval-summary-extract-dom.json)
            dom_score=$(jq '.categories.extract' eval-summary-extract-dom.json)
            echo "DomExtract Score: $dom_score%"
            echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentNameDom}"

            if (( $(echo "$dom_score < 80" | bc -l) )); then
              echo "DomExtract extract category <80%. Failing CI."
              exit 1
            fi
          fi

          # Check textExtract results
          if [ -f eval-summary-extract-text.json ]; then
            experimentNameText=$(jq -r '.experimentName' eval-summary-extract-text.json)
            text_score=$(jq '.categories.extract' eval-summary-extract-text.json)
            echo "TextExtract Score: $text_score%"
            echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentNameText}"
          fi

      ############################################################
      # 7B. TEXT-EXTRACT EVALS (if label = 'text-extract')
      ############################################################
      - name: Run text_extract Evals (textExtract)
        if: ${{ needs.determine-evals.outputs.run-text-extract == 'true' }}
        run: |
          echo "Pretending to run text_extract eval with textExtract..."
          cat <<EOF > eval-summary-text_extract-text.json
          {
            "experimentName": "dummyTextExtract_TextMode",
            "categories": {
              "text_extract": 78
            }
          }
          EOF

      - name: Run text_extract Evals (domExtract)
        if: ${{ needs.determine-evals.outputs.run-text-extract == 'true' }}
        run: |
          echo "Pretending to run text_extract eval with domExtract..."
          cat <<EOF > eval-summary-text_extract-dom.json
          {
            "experimentName": "dummyTextExtract_DomMode",
            "categories": {
              "text_extract": 85
            }
          }
          EOF

      - name: Log and Compare text_extract
        if: ${{ needs.determine-evals.outputs.run-text-extract == 'true' }}
        run: |
          if [ -f eval-summary-text_extract-text.json ]; then
            experimentNameTxt=$(jq -r '.experimentName' eval-summary-text_extract-text.json)
            txt_score=$(jq '.categories.text_extract' eval-summary-text_extract-text.json)
            echo "TextExtract (text_extract) Score: $txt_score%"
            echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentNameTxt}"

            if (( $(echo "$txt_score < 80" | bc -l) )); then
              echo "text_extract score <80%. Failing CI."
              exit 1
            fi
          fi

          if [ -f eval-summary-text_extract-dom.json ]; then
            experimentNameDom=$(jq -r '.experimentName' eval-summary-text_extract-dom.json)
            dom_score=$(jq '.categories.text_extract' eval-summary-text_extract-dom.json)
            echo "DomExtract (text_extract) Score: $dom_score%"
            echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentNameDom}"
          fi

      ############################################################
      # 7C. ACT EVALS (if label = 'act')
      ############################################################
      - name: Run Act Evals
        if: ${{ needs.determine-evals.outputs.run-act == 'true' }}
        run: |
          echo "Pretending to run act eval..."
          cat <<EOF > eval-summary-act.json
          {
            "experimentName": "dummyActEval",
            "categories": {
              "act": 82
            }
          }
          EOF

      - name: Log Act Evals Performance
        if: ${{ needs.determine-evals.outputs.run-act == 'true' }}
        run: |
          experimentName=$(jq -r '.experimentName' eval-summary-act.json)
          echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentName}"
          if [ -f eval-summary-act.json ]; then
            act_score=$(jq '.categories.act' eval-summary-act.json)
            echo "Act category score: $act_score%"
            if (( $(echo "$act_score < 80" | bc -l) )); then
              echo "Act <80%. Failing CI."
              exit 1
            fi
          else
            echo "Eval summary not found. Failing CI."
            exit 1
          fi

      ############################################################
      # 7D. OBSERVE EVALS (if label = 'observe')
      ############################################################
      - name: Run Observe Evals
        if: ${{ needs.determine-evals.outputs.run-observe == 'true' }}
        run: |
          echo "Pretending to run observe eval..."
          cat <<EOF > eval-summary-observe.json
          {
            "experimentName": "dummyObserveEval",
            "categories": {
              "observe": 88
            }
          }
          EOF

      - name: Log Observe Evals Performance
        if: ${{ needs.determine-evals.outputs.run-observe == 'true' }}
        run: |
          experimentName=$(jq -r '.experimentName' eval-summary-observe.json)
          echo "See: https://www.braintrust.dev/app/Browserbase/p/stagehand/experiments/${experimentName}"
          if [ -f eval-summary-observe.json ]; then
            observe_score=$(jq '.categories.observe' eval-summary-observe.json)
            echo "Observe category score: $observe_score%"
            if (( $(echo "$observe_score < 80" | bc -l) )); then
              echo "Observe <80%. Failing CI."
              exit 1
            fi
          else
            echo "Eval summary not found. Failing CI."
            exit 1
          fi
